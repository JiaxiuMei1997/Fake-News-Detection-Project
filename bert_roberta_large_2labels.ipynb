{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RMTW4YxOVj9",
        "outputId": "85d4c38f-7031-4041-c116-e22cfd8783e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_train = pd.read_csv(\"/content/drive/MyDrive/fakenews/fakenews/train.tsv\", sep=\"\\t\", header=None)\n",
        "data_valid = pd.read_csv(\"/content/drive/MyDrive/fakenews/fakenews/valid.tsv\", sep=\"\\t\", header=None)\n",
        "data_test = pd.read_csv(\"/content/drive/MyDrive/fakenews/fakenews/test.tsv\", sep=\"\\t\", header=None)"
      ],
      "metadata": {
        "id": "kXxWAdZ2OmFM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Viewing sample train data before preprocessing\n",
        "data_test.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "Wzju3S_0Omtj",
        "outputId": "a999a6ba-7ddf-4b6d-b118-9101f66e45e5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0           1                                                  2   \\\n",
              "0  11972.json        true  Building a wall on the U.S.-Mexico border will...   \n",
              "1  11685.json       false  Wisconsin is on pace to double the number of l...   \n",
              "2  11096.json       false  Says John McCain has done nothing to help the ...   \n",
              "3   5209.json   half-true  Suzanne Bonamici supports a plan that will cut...   \n",
              "4   9524.json  pants-fire  When asked by a reporter whether hes at the ce...   \n",
              "\n",
              "                                                  3   \\\n",
              "0                                        immigration   \n",
              "1                                               jobs   \n",
              "2                    military,veterans,voting-record   \n",
              "3  medicare,message-machine-2012,campaign-adverti...   \n",
              "4  campaign-finance,legal-issues,campaign-adverti...   \n",
              "\n",
              "                                 4                     5          6   \\\n",
              "0                        rick-perry              Governor      Texas   \n",
              "1                 katrina-shankland  State representative  Wisconsin   \n",
              "2                      donald-trump       President-Elect   New York   \n",
              "3                     rob-cornilles            consultant     Oregon   \n",
              "4  state-democratic-party-wisconsin                   NaN  Wisconsin   \n",
              "\n",
              "           7   8    9   10  11  12                            13  \n",
              "0  republican  30   30  42  23  18               Radio interview  \n",
              "1    democrat   2    1   0   0   0             a news conference  \n",
              "2  republican  63  114  51  37  61  comments on ABC's This Week.  \n",
              "3  republican   1    1   3   1   1                  a radio show  \n",
              "4    democrat   5    7   2   2   7                   a web video  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a38addce-019e-4b9b-923b-8701c2df1e7d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11972.json</td>\n",
              "      <td>true</td>\n",
              "      <td>Building a wall on the U.S.-Mexico border will...</td>\n",
              "      <td>immigration</td>\n",
              "      <td>rick-perry</td>\n",
              "      <td>Governor</td>\n",
              "      <td>Texas</td>\n",
              "      <td>republican</td>\n",
              "      <td>30</td>\n",
              "      <td>30</td>\n",
              "      <td>42</td>\n",
              "      <td>23</td>\n",
              "      <td>18</td>\n",
              "      <td>Radio interview</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11685.json</td>\n",
              "      <td>false</td>\n",
              "      <td>Wisconsin is on pace to double the number of l...</td>\n",
              "      <td>jobs</td>\n",
              "      <td>katrina-shankland</td>\n",
              "      <td>State representative</td>\n",
              "      <td>Wisconsin</td>\n",
              "      <td>democrat</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>a news conference</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11096.json</td>\n",
              "      <td>false</td>\n",
              "      <td>Says John McCain has done nothing to help the ...</td>\n",
              "      <td>military,veterans,voting-record</td>\n",
              "      <td>donald-trump</td>\n",
              "      <td>President-Elect</td>\n",
              "      <td>New York</td>\n",
              "      <td>republican</td>\n",
              "      <td>63</td>\n",
              "      <td>114</td>\n",
              "      <td>51</td>\n",
              "      <td>37</td>\n",
              "      <td>61</td>\n",
              "      <td>comments on ABC's This Week.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5209.json</td>\n",
              "      <td>half-true</td>\n",
              "      <td>Suzanne Bonamici supports a plan that will cut...</td>\n",
              "      <td>medicare,message-machine-2012,campaign-adverti...</td>\n",
              "      <td>rob-cornilles</td>\n",
              "      <td>consultant</td>\n",
              "      <td>Oregon</td>\n",
              "      <td>republican</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>a radio show</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9524.json</td>\n",
              "      <td>pants-fire</td>\n",
              "      <td>When asked by a reporter whether hes at the ce...</td>\n",
              "      <td>campaign-finance,legal-issues,campaign-adverti...</td>\n",
              "      <td>state-democratic-party-wisconsin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Wisconsin</td>\n",
              "      <td>democrat</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>a web video</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a38addce-019e-4b9b-923b-8701c2df1e7d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a38addce-019e-4b9b-923b-8701c2df1e7d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a38addce-019e-4b9b-923b-8701c2df1e7d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Below function performs all the required data cleaning and preprocessing steps\n",
        "\n",
        "def data_preprocessing(dataset):\n",
        "  #Creating new column called 'label' with 1 for true and mostly-true values, else 0 i.e. 1=real, 0=fake\n",
        "  dataset['label']=[1 if x==\"true\"or x==\"mostly-true\" else 0 for x in dataset[1]] \n",
        "  #Dropping unwanted columns\n",
        "  dataset = dataset.drop(labels=[0,1,8,9,10,11,12] ,axis=1)\n",
        "  #Dealing with empty datapoints for metadata columns - subject, speaker, job, state,affiliation, context\n",
        "  meta = []\n",
        "  for i in range(len(dataset)):\n",
        "      subject = dataset[3][i]\n",
        "      if subject == 0:\n",
        "          subject = 'None'\n",
        "\n",
        "      speaker =  dataset[4][i]\n",
        "      if speaker == 0:\n",
        "          speaker = 'None'\n",
        "\n",
        "      job =  dataset[5][i]\n",
        "      if job == 0:\n",
        "          job = 'None'\n",
        "\n",
        "      state =  dataset[6][i]\n",
        "      if state == 0:\n",
        "          state = 'None'\n",
        "\n",
        "      affiliation =  dataset[7][i]\n",
        "      if affiliation == 0:\n",
        "          affiliation = 'None'\n",
        "\n",
        "      context =  dataset[13][i]\n",
        "      if context == 0 :\n",
        "          context = 'None'\n",
        "\n",
        "      meta.append(str(subject) + ' ' + str(speaker) + ' ' + str(job) + ' ' + str(state) + ' ' + str(affiliation) + ' ' + str(context)) #combining all the meta data columns into a single column\n",
        "  \n",
        "  #Adding cleaned and combined metadata column to the dataset\n",
        "  dataset[14] = meta\n",
        "  dataset[\"sentence\"] = dataset[14].astype('str')+\" \"+dataset[2] #Combining metadata and the text columns into single columns\n",
        "\n",
        "  dataset = dataset.drop([2,3,4,5,6,7,13,14], axis=1) #dropping metadata columns, as we have merged them into a single column\n",
        "  dataset.dropna() #Dropping if there are still any null values\n",
        "\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "DQpgw_LLOrn7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying pre-processing to the raw data - train, valid and test sets\n",
        "data_train = data_preprocessing(data_train)\n",
        "data_valid = data_preprocessing(data_valid)\n",
        "data_test = data_preprocessing(data_test)"
      ],
      "metadata": {
        "id": "McIE1NHaOt-K"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample data after preprocessing\n",
        "data_train.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s-DVE50POv7-",
        "outputId": "6821f00f-1199-429d-b083-9b9df15092e9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                           sentence\n",
              "0      0  abortion dwayne-bohac State representative Tex...\n",
              "1      0  energy,history,job-accomplishments scott-surov...\n",
              "2      1  foreign-policy barack-obama President Illinois...\n",
              "3      0  health-care blog-posting nan nan none a news r...\n",
              "4      0  economy,jobs charlie-crist nan Florida democra..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-585d11ee-653d-46a7-a30a-68ee36b3fe73\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>abortion dwayne-bohac State representative Tex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>energy,history,job-accomplishments scott-surov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>foreign-policy barack-obama President Illinois...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>health-care blog-posting nan nan none a news r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>economy,jobs charlie-crist nan Florida democra...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-585d11ee-653d-46a7-a30a-68ee36b3fe73')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-585d11ee-653d-46a7-a30a-68ee36b3fe73 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-585d11ee-653d-46a7-a30a-68ee36b3fe73');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyzing length of sentences in training data to decide on MAX_LENGTH variable, which is required for BERT and RoBERTa\n",
        "\n",
        "sent_len = []\n",
        "for sent in data_train['sentence']:\n",
        "  sent_len.append(len(sent))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize =(10, 7))\n",
        "plt.boxplot(sent_len)\n",
        "plt.show()\n",
        "\n",
        "sent_len = [i for i in sent_len if i<=500] #Excluding the outliers\n",
        "fig2 = plt.figure(figsize =(10, 7))\n",
        "plt.hist(sent_len, 5)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "id": "c8lybc9KOyyW",
        "outputId": "eead65ed-20b3-47fc-d3a9-9acadffec92f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCHdtxWPO6IU",
        "outputId": "3f39547e-aae5-480b-b147-e3194c27945a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing required packages  \n",
        "from transformers import (\n",
        "    BertForSequenceClassification,    \n",
        "    BertTokenizer,\n",
        "    RobertaForSequenceClassification,\n",
        "    RobertaTokenizer,\n",
        "    AdamW)"
      ],
      "metadata": {
        "id": "33GkdGoqO8pX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading BERT base model\n",
        "bert_model = BertForSequenceClassification.from_pretrained(\"bert-large-uncased\", #Using BERT base model with an uncased vocab.\n",
        "                                                                num_labels = 2, #number of output labels - 0,1 (binary classification)\n",
        "                                                                output_attentions = False, #model doesnt return attention weights\n",
        "                                                                output_hidden_states = False #model doesnt return hidden states\n",
        "                                                          )\n",
        "#BERT tokenizer\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased\", do_lower_case=True)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "bert_model.cuda()"
      ],
      "metadata": {
        "id": "9WWEUDCWO_Ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', data_train[\"sentence\"][0])\n",
        "\n",
        "# Split the sentence into tokens - BERT\n",
        "print('Tokenized BERT: ', bert_tokenizer.tokenize(data_train[\"sentence\"][0]))\n",
        "\n",
        "# Mapping tokens to token IDs - BERT\n",
        "print('Token IDs BERT: ', bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize(data_train[\"sentence\"][0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNA8GCuXPDlm",
        "outputId": "285eb463-6276-4354-c530-f2b15082b80c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  abortion dwayne-bohac State representative Texas republican a mailer Says the Annies List political group supports third-trimester abortions on demand.\n",
            "Tokenized BERT:  ['abortion', 'd', '##way', '##ne', '-', 'bo', '##ha', '##c', 'state', 'representative', 'texas', 'republican', 'a', 'mail', '##er', 'says', 'the', 'annie', '##s', 'list', 'political', 'group', 'supports', 'third', '-', 'trim', '##ester', 'abortion', '##s', 'on', 'demand', '.']\n",
            "Token IDs BERT:  [11324, 1040, 4576, 2638, 1011, 8945, 3270, 2278, 2110, 4387, 3146, 3951, 1037, 5653, 2121, 2758, 1996, 8194, 2015, 2862, 2576, 2177, 6753, 2353, 1011, 12241, 20367, 11324, 2015, 2006, 5157, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#assigning sentences and labels to separate variables\n",
        "sentences = data_train[\"sentence\"].values\n",
        "labels = data_train[\"label\"].values"
      ],
      "metadata": {
        "id": "v5sYNVypPUw7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "SSPR4zH2PWcm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Below function performs tokenization process as required by bert and roberta models, for a given dataset\n",
        "def bert_robert_tokenization(dataset):\n",
        "  sentences = dataset[\"sentence\"].values\n",
        "  labels = dataset[\"label\"].values\n",
        "  max_length = 256\n",
        "\n",
        "  # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "  bert_input_ids = []\n",
        "  bert_attention_masks = []\n",
        "  roberta_input_ids = []\n",
        "  roberta_attention_masks = []\n",
        "\n",
        "  sentence_ids = []\n",
        "  counter = 0\n",
        "\n",
        "  # For every sentence...\n",
        "  for sent in sentences:\n",
        "      #encode_plus function will encode the sentences as required by model, including tokenization process and mapping token ids\n",
        "      bert_encoded_dict = bert_tokenizer.encode_plus(\n",
        "                          str(sent),        #sentence              \n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]' tokens \n",
        "                          max_length = 256,     #Since we have seen from our analysis that majority of sentences have length less than 300.    \n",
        "                          pad_to_max_length = True,    # Pad sentences to 256 length  if the length of sentence is less than max_length\n",
        "                          return_attention_mask = True,   # Create attention mask\n",
        "                          truncation = True,  # truncate sentences to 256 length  if the length of sentence is greater than max_length\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                    )      \n",
        "    \n",
        "      # Add the encoded sentence to the list.    \n",
        "      bert_input_ids.append(bert_encoded_dict['input_ids'])\n",
        "      #roberta_input_ids.append(roberta_encoded_dict['input_ids'])\n",
        "      \n",
        "      \n",
        "      # Add attention mask to the list \n",
        "      bert_attention_masks.append(bert_encoded_dict['attention_mask'])\n",
        "      #roberta_attention_masks.append(roberta_encoded_dict['attention_mask'])\n",
        "      \n",
        "      \n",
        "      # collecting sentence_ids\n",
        "      sentence_ids.append(counter)\n",
        "      counter  = counter + 1\n",
        "      \n",
        "      \n",
        "      \n",
        "  # Convert the lists into tensors.\n",
        "  bert_input_ids = torch.cat(bert_input_ids, dim=0)\n",
        "  bert_attention_masks = torch.cat(bert_attention_masks, dim=0)\n",
        "\n",
        "  #roberta_input_ids = torch.cat(roberta_input_ids, dim=0)\n",
        "  #roberta_attention_masks = torch.cat(roberta_attention_masks, dim=0)\n",
        "\n",
        "\n",
        "  labels = torch.tensor(labels)\n",
        "  sentence_ids = torch.tensor(sentence_ids)\n",
        "\n",
        "  return {\"Bert\":[bert_input_ids, bert_attention_masks, labels]}"
      ],
      "metadata": {
        "id": "8l5QmH9lPZoX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "# function to seed the script globally\n",
        "torch.manual_seed(0)\n",
        "\n",
        "#tokenizing train set\n",
        "token_dict_train = bert_robert_tokenization(data_train)\n",
        "\n",
        "bert_input_ids,bert_attention_masks,labels = token_dict_train[\"Bert\"]\n",
        "#roberta_input_ids, roberta_attention_masks, labels = token_dict_train[\"Roberta\"]\n",
        "\n",
        "#tokenizing validation set\n",
        "token_dict_valid = bert_robert_tokenization(data_valid)\n",
        "\n",
        "bert_input_ids_valid,bert_attention_masks_valid,labels_valid = token_dict_valid[\"Bert\"]\n",
        "#roberta_input_ids_valid, roberta_attention_masks_valid, labels_valid = token_dict_valid[\"Roberta\"]\n",
        "\n",
        "#tokenizing test set\n",
        "token_dict_test = bert_robert_tokenization(data_test)\n",
        "\n",
        "bert_input_ids_test,bert_attention_masks_test,labels_test = token_dict_test[\"Bert\"]\n",
        "#roberta_input_ids_test, roberta_attention_masks_test, labels_test = token_dict_test[\"Roberta\"]"
      ],
      "metadata": {
        "id": "y4b9eRgoPcIw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the training inputs into a TensorDataset.\n",
        "bert_train_dataset = TensorDataset( bert_input_ids, bert_attention_masks, labels) \n",
        "#roberta_train_dataset = TensorDataset(roberta_input_ids, roberta_attention_masks, labels)\n",
        "\n",
        "# Combine the validation inputs into a TensorDataset.\n",
        "bert_val_dataset = TensorDataset(bert_input_ids_valid,bert_attention_masks_valid,labels_valid)\n",
        "#roberta_val_dataset = TensorDataset(roberta_input_ids_valid, roberta_attention_masks_valid, labels_valid)"
      ],
      "metadata": {
        "id": "2aDOMHgrPeh6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the test inputs into a TensorDataset.\n",
        "bert_test_dataset = TensorDataset(bert_input_ids_test,bert_attention_masks_test,labels_test)\n",
        "#roberta_test_dataset = TensorDataset(roberta_input_ids_test, roberta_attention_masks_test, labels_test)"
      ],
      "metadata": {
        "id": "gDmRWbLHPgy0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training - Loads the data randomly in batches of size 32\n",
        "bert_train_dataloader = DataLoader(\n",
        "            bert_train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(bert_train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# Create the DataLoaders for our validation - Loads the data in batches of size 32\n",
        "bert_validation_dataloader = DataLoader(\n",
        "            bert_val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(bert_val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "yZ2E_KbtPjKz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizers - AdamW\n",
        "# here, i have used default learning rate and epsilon values for both BERT and RoBERTa\n",
        "bert_optimizer = AdamW(bert_model.parameters(),\n",
        "                  lr = 5e-5, \n",
        "                  eps = 1e-8 \n",
        "                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqA26dBPPjy4",
        "outputId": "29efb8f8-a25f-4868-a0c5-f2fda4529ed6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs\n",
        "epochs = 2\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]\n",
        "total_steps = len(bert_train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "bert_scheduler = get_linear_schedule_with_warmup(bert_optimizer, \n",
        "                                            num_warmup_steps = 0, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "wvemOIYoPni3"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "x75Sv1tJPoNp"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "8bfA5r-nPqb8"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# tell pytorch to use the gpu if available\n",
        "if torch.cuda.is_available():    \n",
        "      \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4sobMyIPt8X",
        "outputId": "33f5f534-89e7-4c67-db51-950b10158355"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "loss_values = []\n",
        "for epoch_i in range(0, epochs):\n",
        "    #Training \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "    bert_model.train()\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(bert_train_dataloader):\n",
        "      #Report progress after every 40 epochs\n",
        "        if step % 40 == 0 and not step == 0: \n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # print current training batch and elapsed time\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(bert_train_dataloader), elapsed))\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        bert_model.zero_grad()        \n",
        "        \n",
        "        outputs = bert_model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # model returns a tuple, extract loss value from that tuple\n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(bert_model.parameters(), 1.0)\n",
        "        bert_optimizer.step()\n",
        "        \n",
        "        bert_scheduler.step()\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(bert_train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    #Validation Part\n",
        "\n",
        "    \n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "    t0 = time.time()\n",
        "    # Put the model in evaluation mode    \n",
        "    bert_model.eval()\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in bert_validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "           outputs = bert_model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        logits = outputs[0]\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "rUel2lMYPxQB",
        "outputId": "f15b797e-bdf6-48c6-8027-0d73441bba42"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-f9c604f545c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mbert_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         outputs = bert_model(b_input_ids, \n\u001b[0m\u001b[1;32m     38\u001b[0m                     \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1561\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1564\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         )\n\u001b[0;32m-> 1019\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1020\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    607\u001b[0m                 )\n\u001b[1;32m    608\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    610\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    538\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/activations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 14.76 GiB total capacity; 13.88 GiB already allocated; 97.88 MiB free; 13.89 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the training loss over epochs\n",
        "import plotly.express as px\n",
        "f = pd.DataFrame(loss_values)\n",
        "f.columns=['Loss']\n",
        "fig = px.line(f, x=f.index, y=f.Loss)\n",
        "fig.update_layout(title='Training loss of the Model',\n",
        "                   xaxis_title='Epoch',\n",
        "                   yaxis_title='Loss')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "UD3Jxj4APz0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_prediction_sampler = SequentialSampler(bert_test_dataset)\n",
        "bert_prediction_dataloader = DataLoader(bert_test_dataset, sampler=bert_prediction_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "FyIPrRZ9P1s2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(bert_input_ids_test)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "bert_model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []"
      ],
      "metadata": {
        "id": "58_IOpDSP3ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict \n",
        "for batch in bert_prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        " \n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = bert_model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "print('    DONE.')"
      ],
      "metadata": {
        "id": "-1zScvrCP5xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_labels = [item for subitem in predictions for item in subitem]\n",
        "\n",
        "predictions_labels = np.argmax(predictions_labels, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print (classification_report(predictions_labels, flat_true_labels))\n",
        "print(confusion_matrix(flat_true_labels, predictions_labels))"
      ],
      "metadata": {
        "id": "wjiBCHeaP8A8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}